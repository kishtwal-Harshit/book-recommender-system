{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d4200f5-7063-4968-9e6b-2e315d4a226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91821\\AppData\\Local\\Temp\\ipykernel_23944\\645974441.py:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('Books.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f98f05f-cf15-43f9-a22e-026e5ac7ee0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91821\\AppData\\Local\\Temp\\ipykernel_34216\\3372089777.py:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('books.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Animal Farm', 'George Orwell', 'http://images.amazon.com/images/P/0451526341.01.MZZZZZZZ.jpg'], [\"The Handmaid's Tale\", 'Margaret Atwood', 'http://images.amazon.com/images/P/0449212602.01.MZZZZZZZ.jpg'], ['Brave New World', 'Aldous Huxley', 'http://images.amazon.com/images/P/0060809833.01.MZZZZZZZ.jpg'], ['The Vampire Lestat (Vampire Chronicles, Book II)', 'ANNE RICE', 'http://images.amazon.com/images/P/0345313860.01.MZZZZZZZ.jpg']]\n",
      "User-ID              254     2276    2766    2977    3363    4017    4385    \\\n",
      "Book-Title                                                                    \n",
      "1984                    9.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1st to Die: A Novel     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2nd Chance              0.0    10.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4 Blondes               0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "A Bend in the Road      0.0     0.0     7.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "User-ID              6251    6323    6543    ...  271705  273979  274004  \\\n",
      "Book-Title                                   ...                           \n",
      "1984                    0.0     0.0     0.0  ...    10.0     0.0     0.0   \n",
      "1st to Die: A Novel     0.0     0.0     9.0  ...     0.0     0.0     0.0   \n",
      "2nd Chance              0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "4 Blondes               0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "A Bend in the Road      0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
      "\n",
      "User-ID              274061  274301  274308  275970  277427  277639  278418  \n",
      "Book-Title                                                                   \n",
      "1984                    0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "1st to Die: A Novel     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2nd Chance              0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "4 Blondes               0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "A Bend in the Road      0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 810 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "books = pd.read_csv('books.csv')\n",
    "users = pd.read_csv('users.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Check for any null values\n",
    "books.isnull().sum()\n",
    "users.isnull().sum()\n",
    "ratings.isnull().sum()\n",
    "\n",
    "# Merge ratings with book details\n",
    "ratings_with_name = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Count number of ratings per book\n",
    "num_rating_df = ratings_with_name.groupby('Book-Title').count()['Book-Rating'].reset_index()\n",
    "num_rating_df.rename(columns={'Book-Rating': 'num_ratings'}, inplace=True)\n",
    "\n",
    "# Calculate average rating per book (only 'Book-Rating' column is considered)\n",
    "avg_rating_df = ratings_with_name.groupby('Book-Title')['Book-Rating'].mean().reset_index()\n",
    "avg_rating_df.rename(columns={'Book-Rating': 'avg_rating'}, inplace=True)\n",
    "\n",
    "# Merge number of ratings and average ratings, filter popular books\n",
    "popular_df = num_rating_df.merge(avg_rating_df, on='Book-Title')\n",
    "popular_df = popular_df[popular_df['num_ratings'] >= 250].sort_values('avg_rating', ascending=False).head(50)\n",
    "popular_df = popular_df.merge(books, on='Book-Title').drop_duplicates('Book-Title')[['Book-Title', 'Book-Author', 'Image-URL-M', 'num_ratings', 'avg_rating']]\n",
    "\n",
    "# Collaborative Filtering Based Recommender System\n",
    "# Filter users with more than 200 ratings\n",
    "x = ratings_with_name.groupby('User-ID').count()['Book-Rating'] > 200\n",
    "authentic_users = x[x].index\n",
    "filtered_rating = ratings_with_name[ratings_with_name['User-ID'].isin(authentic_users)]\n",
    "\n",
    "# Filter books with more than 50 ratings\n",
    "y = filtered_rating.groupby('Book-Title').count()['Book-Rating'] >= 50\n",
    "famous_books = y[y].index\n",
    "final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)]\n",
    "\n",
    "# Create a pivot table\n",
    "pt = final_ratings.pivot_table(index='Book-Title', columns='User-ID', values='Book-Rating')\n",
    "pt.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate similarity scores\n",
    "similarity_scores = cosine_similarity(pt)\n",
    "\n",
    "# Recommendation function\n",
    "def recommend(book_name):\n",
    "    # Fetch index of the book\n",
    "    if book_name not in pt.index:\n",
    "        return f\"Book '{book_name}' not found in the dataset.\"\n",
    "    index = np.where(pt.index == book_name)[0][0]\n",
    "    similar_items = sorted(list(enumerate(similarity_scores[index])), key=lambda x: x[1], reverse=True)[1:5]\n",
    "    \n",
    "    # Compile recommended books data\n",
    "    data = []\n",
    "    for i in similar_items:\n",
    "        item = []\n",
    "        temp_df = books[books['Book-Title'] == pt.index[i[0]]]\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))\n",
    "        data.append(item)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Test the recommendation function\n",
    "print(recommend('1984'))\n",
    "\n",
    "# Save the necessary data\n",
    "#import pickle\n",
    "pickle.dump(popular_df, open(r'C:\\book-recommender-system\\pythonProject1\\popular.pkl', 'wb'))\n",
    "\n",
    "#pickle.dump(popular_df, open('popular.pkl', 'wb'))\n",
    "pickle.dump(pt, open(r'C:\\book-recommender-system\\pythonProject1\\pt.pkl', 'wb'))\n",
    "pickle.dump(books.drop_duplicates('Book-Title'), open(r'C:\\book-recommender-system\\pythonProject1\\books.pkl', 'wb'))\n",
    "pickle.dump(similarity_scores, open(r'C:\\book-recommender-system\\pythonProject1\\similarity_scores.pkl', 'wb'))\n",
    "\n",
    "data = pickle.load(open(r'C:\\book-recommender-system\\pythonProject1\\pt.pkl', 'rb'))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d2df5-4c7c-45eb-96a5-33cc838e87b6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfb03ce7-4a12-4a89-b19b-9bc1af50ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular DF loaded successfully\n",
      "Pivot table (pt) loaded successfully\n",
      "Books DF loaded successfully\n",
      "Similarity scores loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    popular_df = pickle.load(open('popular.pkl', 'rb'))\n",
    "    print(\"Popular DF loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading popular.pkl:\", e)\n",
    "\n",
    "try:\n",
    "    pt = pickle.load(open('pt.pkl', 'rb'))\n",
    "    print(\"Pivot table (pt) loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading pt.pkl:\", e)\n",
    "\n",
    "try:\n",
    "    books = pickle.load(open('books.pkl', 'rb'))\n",
    "    print(\"Books DF loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading books.pkl:\", e)\n",
    "\n",
    "try:\n",
    "    similarity_scores = pickle.load(open('similarity_scores.pkl', 'rb'))\n",
    "    print(\"Similarity scores loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading similarity_scores.pkl:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cbc83-a953-4eb7-a506-fe48fe6955cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e85f3-948a-4259-9c7a-cf8a603f984e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
